{
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "name": "",
  "signature": "sha256:e090a810380a4028e6a292dce374f38b9533f02e5f389e3f4fd5fda698af12ca"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Topic Modelling Example\n"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Requirements: \n",
      "    Scipy \n",
      "    Numpy\n",
      "    gensim\n",
      "Installation Steps:\n",
      "    easy_install numpy\n",
      "    easy_install scipy\n",
      "    easy_install gensim"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The dataset used are the titles and topic codes from the NYTimes dataset that comes with the RTextTools library in R. It consists of titles from NYTimes front page news and associated codes according to Amber Boydstun's classification scheme.\n",
      "\n",
      "Download data from:\n",
      "https://github.com/timjurka/RTextTools/blob/master/RTextTools/data/NYTimes.csv.gz"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Gensim can be applied to large datasets as it incorporates both the online version of LDA and distributed computing capability.\n",
      "\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Import Libraries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gensim import corpora, models, similarities\n",
      "from operator import itemgetter\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load Stopword List"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "stoplist=[\"a\",\"able\",\"about\",\"across\",\"after\",\"all\",\"try\",\"bye\",\"almost\",\"also\",\"am\",\"among\",\"an\",\"and\",\"any\",\"are\",\"as\",\"at\",\"be\",\"because\",\"been\",\"but\",\"by\",\"can\",\"cannot\",\"could\",\"dear\",\"did\",\"do\",\"does\",\"either\",\"else\",\"ever\",\"every\",\"for\",\"from\",\"get\",\"got\",\"had\",\"has\",\"have\",\"he\",\"her\",\"hers\",\"him\",\"his\",\"how\",\"however\",\"i\",\"if\",\"in\",\"into\",\"is\",\"it\",\"its\",\"just\",\"least\",\"let\",\"like\",\"likely\",\"may\",\"me\",\"might\",\"most\",\"must\",\"my\",\"neither\",\"no\",\"nor\",\"not\",\"of\",\"off\",\"often\",\"on\",\"only\",\"or\",\"other\",\"our\",\"own\",\"rather\",\"said\",\"say\",\"says\",\"she\",\"should\",\"since\",\"so\",\"some\",\"than\",\"that\",\"the\",\"their\",\"them\",\"then\",\"there\",\"these\",\"they\",\"this\",\"tis\",\"to\",\"too\",\"twas\",\"us\",\"wants\",\"was\",\"we\",\"were\",\"what\",\"when\",\"where\",\"which\",\"while\",\"who\",\"whom\",\"why\",\"will\",\"with\",\"would\",\"yet\",\"you\",\"your\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Load NYTimes Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Replace the filename with the corresponding location in your computer"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "nyt_data = []\n",
      "with open('/Users/pralav/Documents/Projects/Owned/DeepWiki/static/NYTimes.csv') as f:\n",
      "    lines=f.readlines()\n",
      "for line in lines:\n",
      "    data=filter(None,line.split(\";\"))\n",
      "    nyt_data.append(data[2].replace('\"',''))\n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Split the document into words and Remove Stopwords"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = [document for document in nyt_data]\n",
      "texts = [[word for word in document.lower().split() if word not in stoplist and not word.isdigit()]\n",
      "         for document in documents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create Vocabulary from the text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary = corpora.Dictionary(texts)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Vectorize the document based on words in Vocabulary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus = [dictionary.doc2bow(text) for text in texts]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create TFIDF Vectors of the corpus created"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = models.TfidfModel(corpus)\n",
      "corpus_tfidf = tfidf[corpus]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create LDA Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n_topics = 50\n",
      "lda = models.LdaModel(corpus_tfidf, id2word=dictionary, num_topics=n_topics,iterations=200)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Show Topics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(0, n_topics):\n",
      "    temp = lda.show_topic(i, 10)\n",
      "    terms = []\n",
      "    for term in temp:\n",
      "        terms.append(term[1])\n",
      "    print \"Top 10 terms for topic #\" + str(i) + \": \"+ \", \".join(terms)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Top 10 terms for topic #0: loss, shuttle:, web, cities, longtime, health, feeling, poor, taxes, syria\n",
        "Top 10 terms for topic #1: home, goes, city, bush's, pension, british, stem, bush, going, another\n",
        "Top 10 terms for topic #2: old, g.o.p., leaders, guilty, slain, calls, tough, charter, hunting, setback\n",
        "Top 10 terms for topic #3: security, rivals, overview, democrats, message, new, bill, millions, boston, senate\n",
        "Top 10 terms for topic #4: c.i.a., force, murder, killings, talks, stall, beijing, agency, pakistani, head\n",
        "Top 10 terms for topic #5: make, army, beaten, iraq, panel, subway, pressure, schools, deep, meet\n",
        "Top 10 terms for topic #6: case, palestinian, inflamed:, sharon, region, gay, polls, california, reconstruction, schools,\n",
        "Top 10 terms for topic #7: rise, violence, house, delay, congressional, tax, chief, boom, cut, school\n",
        "Top 10 terms for topic #8: technology, lost, museum, california, hint, hurdles, prices, attacking, trade, consider\n",
        "Top 10 terms for topic #9: iran, seat, u.s., europe, florida, fight, both, doesn't, sell, turning\n",
        "Top 10 terms for topic #10: threats, responses:, bowl, strategy, college, vanished, sports, chairman, no., times\n",
        "Top 10 terms for topic #11: baghdad, kills, marines, bombing, network, london, death, ill, weapon, afghanistan\n",
        "Top 10 terms for topic #12: farewell, zero, ground, line, online, closing, elderly, drugs, economy,, ordered\n",
        "Top 10 terms for topic #13: last, star, charming, born, fail, policy, populist, uses, food, women\n",
        "Top 10 terms for topic #14: politics, iraq's, power, pain, senate, war, battle, target, leader, germany\n",
        "Top 10 terms for topic #15: baseball, rumsfeld, one, holds, iraq, changes, arms, premier, risks, international\n",
        "Top 10 terms for topic #16: push, iraq,, right, hussein, baby, money, u.s., bus, qaeda, equal\n",
        "Top 10 terms for topic #17: baghdad, group, nation, u.s., afghanistan, lawyers, fears, pakistan, giants, choice\n",
        "Top 10 terms for topic #18: call, bold, health, cost, dies, palestinians, voices, insurance, court, pick\n",
        "Top 10 terms for topic #19: iraqis, g.i.'s, widens, gas, aide, block, finally, loses, shots, sense"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Top 10 terms for topic #20: democrats, election, die, puts, final, ., leader, poll, offensive, rights\n",
        "Top 10 terms for topic #21: attack, aftereffects:, record, vote, u.s.,, abuse, faces, executives, coach, priests\n",
        "Top 10 terms for topic #22: work, defense, attack, brooklyn, injuries, name, cardinals, foes, ship, note\n",
        "Top 10 terms for topic #23: iraq:, struggle, prison, embrace, resigns, new, f.b.i., jersey, abuse, program\n",
        "Top 10 terms for topic #24: seek, ready, jail, lebanon, lag, avoid, legal, cards, fighting, vast\n",
        "Top 10 terms for topic #25: death, raise, officials, again, reality, terrorist, now, enters, new, plan\n",
        "Top 10 terms for topic #26: increase, rule, chinese, united, court:, next, supreme, toll, power, groups\n",
        "Top 10 terms for topic #27: 9/11, capital, washington, estimate, audit, focus, plans, share, victims, gave\n",
        "Top 10 terms for topic #28: analysis, news, run, rebel, out, responses:, backs, ousted, struggle, flag\n",
        "Top 10 terms for topic #29: tribunal, rebels, official, still, investors, scramble, economy, batter, stocks, back\n",
        "Top 10 terms for topic #30: take, troops, life, football, influence, coast, boom, crisis, town, nato\n",
        "Top 10 terms for topic #31: terror, seeking, young, bush,, family, seen, tough, generals, paid, season\n",
        "Top 10 terms for topic #32: attacks, seem, hard, laden, bin, seek, over, toward, wealth, eve\n",
        "Top 10 terms for topic #33: victory, nuclear, airlines, inspections, terrorism, benefit, india, threats, gaza, united\n",
        "Top 10 terms for topic #34: go, down, golf, shadow, madrid, remain, republicans, latest, business, bombings\n",
        "Top 10 terms for topic #35: iraq, bloomberg, war, mayor, hurricane, days, spending, seeks, loom, labor\n",
        "Top 10 terms for topic #36: iraq, 9/11, aid, oil, offer, bush, link, around, alliance, attack\n",
        "Top 10 terms for topic #37: nation, up, day, president, troops, congress, fighting, led, water, nears\n",
        "Top 10 terms for topic #38: bush, inquiry, dies, files, senator, bombs, slow, israel, end, backs"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Top 10 terms for topic #39: see, pentagon, raids, win, turn, fallen, station, evidence, india's, palestinians\n",
        "Top 10 terms for topic #40: sept., intelligence, orders, questions, weapons, changes, delays, status, girls, asserts\n",
        "Top 10 terms for topic #41: keep, site, ties, domestic, employers, million, suspect, use, u.s., proposal\n",
        "Top 10 terms for topic #42: help, charges, return, west, freed, asian, plans, strip, cabinet, clinton\n",
        "Top 10 terms for topic #43: war:, race, role, behind, left, inside, scene, leak, combat, out\n",
        "Top 10 terms for topic #44: years, military, bankruptcy, transit, senators, data, close, public, chance, cuba\n",
        "Top 10 terms for topic #45: suicide, storm, bonus, bomber, vote, rally, gulf, set, change, florida\n",
        "Top 10 terms for topic #46: party, battle, cleric, before, cash, makes, abortion, woman, iowa, water\n",
        "Top 10 terms for topic #47: report, police, clash, general, sites, memo, shows, two, political, officer\n",
        "Top 10 terms for topic #48: costs, inflation, more, rush, gaza, homeless, issues, surges, challenges, large\n",
        "Top 10 terms for topic #49: top, search, getting, cases, even, won't, sets, third, job, new\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Another Example : 20 news groups data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.datasets import fetch_20newsgroups\n",
      "from pprint import pprint\n",
      "import re\n",
      "from gensim.models import ldamodel, TfidfModel\n",
      "data = fetch_20newsgroups(subset='train')\n",
      "pprint(list(data.target_names))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['alt.atheism',\n",
        " 'comp.graphics',\n",
        " 'comp.os.ms-windows.misc',\n",
        " 'comp.sys.ibm.pc.hardware',\n",
        " 'comp.sys.mac.hardware',\n",
        " 'comp.windows.x',\n",
        " 'misc.forsale',\n",
        " 'rec.autos',\n",
        " 'rec.motorcycles',\n",
        " 'rec.sport.baseball',\n",
        " 'rec.sport.hockey',\n",
        " 'sci.crypt',\n",
        " 'sci.electronics',\n",
        " 'sci.med',\n",
        " 'sci.space',\n",
        " 'soc.religion.christian',\n",
        " 'talk.politics.guns',\n",
        " 'talk.politics.mideast',\n",
        " 'talk.politics.misc',\n",
        " 'talk.religion.misc']\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Split Words, Create Dictionary, Remove Stopwords"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents = [[w.lower() for w in re.findall('[a-zA-Z]{4,}', doc)] for doc in data.data]\n",
      "documents = [d[:200] for d in documents]\n",
      "dictionary = corpora.Dictionary(documents)\n",
      "\n",
      "\n",
      "stop_ids = [dictionary.token2id[stopword] for stopword in stoplist if stopword in dictionary.token2id]\n",
      "once_ids = [tokenid for tokenid, docfreq in dictionary.dfs.iteritems() if docfreq == 1 and len(dictionary[tokenid])<=2]\n",
      "dictionary.filter_tokens(stop_ids + once_ids)\n",
      "dictionary.compactify()\n",
      "corpus = [dictionary.doc2bow(text) for text in documents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "TFIDF from data:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tfidf = TfidfModel(corpus)\n",
      "corpus_tfidf = tfidf[corpus]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Create LDA Model from Corpus and Print Topics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda = ldamodel.LdaModel(corpus_tfidf, num_topics=20,iterations=100)\n",
      "i = 0\n",
      "# We print the topics\n",
      "for topic in lda.show_topics(num_topics=20, formatted=False,num_words=20):\n",
      "    i = i + 1\n",
      "    print \"Topic #\" + str(i) + \":\",\n",
      "    c=0\n",
      "    for p, id in topic:\n",
      "        if len(dictionary[int(id)])>2:\n",
      "            print dictionary[int(id)],\n",
      "    print \"\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:no word id mapping provided; initializing from corpus, assuming identity\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Topic #1: government caltech clinton people president armenians cramer turkish optilink press ncsu federal population california encryption armenian think ripem administration states \n",
        "Topic #2: people jesus believe bible sandvik christians church christ christian think many being hell life those more right religion such things \n",
        "Topic #3: radar detector beauchaine bobbe vice zionism thou tseng concordia virgin catcher petch detectors mary cherry ingres howland queens ists sank \n",
        "Topic #4: cleveland cwru freenet buffalo israeli western israel reserve convex arab case houses food adobe stanford bike factory ubvmsb carleton medical \n",
        "Topic #5: comet kaldis engr sphere cacs jupiter orbit monitor fraering speedy gehrels latech mcmaster rosicrucian louisiana umass temporary points hpfcso trucks \n",
        "Topic #6: keith dtmedin catbyte rtsg svoboda ingr caltech oswego chinet homosexuals gainey cruel philips mangoe goyal hfsi allan ritvax halcyon marks \n",
        "Topic #7: alaska magnus ohio window gtoal aurora animation nsmca graham state monash clarinet tammy acad randy dresden purdue expose shearson brad \n",
        "Topic #8: henry toronto hulman billion handheld helmet noah psuvm higgins zoology captain space edmonton east spencer danny blues solar rose robbie \n",
        "Topic #9: umich bike behanna centerline engin prize portal cycle chris psilink victor frost cooling hook leather wave jack liability harddisk cern \n",
        "Topic #10: fnal utexas ether temple ualberta compaq astro rocket angmar berkeley ctrl milwaukee slip gerard navy mental cosmo marty subscribe twisto \n",
        "Topic #11: cunixb columbia gary dare islanders devils wesleyan tartarus sequent techbook selanne winnipeg animal penguins espn orioles stanley jets manhattan hall \n",
        "Topic #12: andrew bobby callison hockey halat feustel team mozumder ultb xputimage laurentian maynard atheism breaker pittsburgh sticker journalism cleveland ramsey indiana \n",
        "Topic #13: baalke umcc stafford winona sequences sternlight adcom coprocessor gothamcity kelvin wireless probert globe columbia magellan spacecraft jhunix echo kean strnlght \n",
        "Topic #14: hudson duke udel marriage revelation jews okcforum midi images infante married bureau uvic cousineau osrhe ryan atheism grace questions sale \n",
        "Topic #15: adobe protocol melbourne motorcycle wings aftermarket fonts nagle cornell nichols rmit seca game sage karr rose ucar hellman espn blacks \n",
        "Topic #16: escrow chip clipper encrypted upenn rauser input keys crypto bits richard diablo secret militia algorithm serial keller warrant mail europeans \n",
        "Topic #17: banks gordon pitt cadre shameful surrender skepticism chastity intellect clas virginia lciii univ convertible rind soon wray faraday sunysb mpeg \n",
        "Topic #18: windows drive card system thanks need anyone university please know software help work mail problem access graphics computer netcom using \n",
        "Topic #19: dyer ohio princeton uicvm state sexual glock spdcc homosexual mars drugs uchicago magnus purdue shipping drum msstate mary liar easter \n",
        "Topic #20: team game games hockey baseball harvard year doug yale teams fans university objective uiuc season berkeley play cornell last detroit \n"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}